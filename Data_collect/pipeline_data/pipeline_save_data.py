import os, requests, dotenv, psycopg2, schedule, logging, time
from datetime import datetime
import pandas as pd
from dotenv import load_dotenv

# charger les variables d'environnement depuis le fichier .env
load_dotenv()

# settings of database
DB_PARAMS = {
    "host": os.getenv("host"),
    "dbname": os.getenv("dbname"),
    "user": os.getenv("user"),
    "password": os.getenv("password"),
    "port": os.getenv("port")
}
dir_file = "Dataset"
file_dir = os.path.join(dir_file, "True_news.csv")
def automatise_data_save():
    try:
        connection_data = psycopg2.connect(**DB_PARAMS)
        cursor_server = connection_data.cursor()

        cursor_server.execute("SELECT title, description, author, content, published_at, source, category FROM news;")
        data_rows = cursor_server.fetchall()

        data_columns = [col[0] for col in cursor_server.description]

        df = pd.DataFrame(data_rows, columns=data_columns)
        os.makedirs(dir_file, exist_ok=True)  # create directory if it doesn't exist
        # save to csv
        df.to_csv(file_dir, index=False)

        logging.info("Data updated !!")
        cursor_server.close()
        connection_data.close()
    except Exception as e:
        logging.error(f"Error of saving data {e}")

schedule.every(1).minutes.do(automatise_data_save)

# Boucle principale
if __name__ == "__main__":
    print("ðŸš€ DÃ©marrage de sauvegarde des donnÃ©es from supabase (intervalle : 1 min)...")
    automatise_data_save()  # exÃ©cution initiale
    while True:
        schedule.run_pending()
        time.sleep(1)
